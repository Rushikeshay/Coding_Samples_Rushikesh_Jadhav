## ----setup, include=FALSE------------------------------------------------------------------------------
knitr::opts_chunk$set(echo = TRUE)


## ------------------------------------------------------------------------------------------------------
#Libraries 
suppressPackageStartupMessages({
  library(foreign)
  library(haven)
  library(dplyr)
  library(tidyr)
  library(stringr)
  library(stargazer)
  library(broom)
  library(sandwich)  
  library(lmtest)
  library(AER)
  library(knitr)
  library(car)
  library(ggplot2)
  library(readxl)
})


## ------------------------------------------------------------------------------------------------------
setwd("C:/Users/rushi/OneDrive - The University of Chicago/Spring 2025-Jadhav-DellXPS-13/Adv. Program Eval/PS 4")
file_path <- "tables_1_5_comb.xlsx"
lopez_df <- read_excel(file_path, sheet = "Indicators_only")

## ------------------------------------------------------------------------------------------------------
# Changing the indicators names to separate I-1 to I-22 from table 5. I am appending 
# .5 to I-1 to I-22 for table 5 indicators to separate them.  

lopez_df$Indicators[44:nrow(lopez_df)] <- sub(
  pattern = "^I-(\\d+)\\.", 
  replacement = "I-\\1.5.", 
  x = lopez_df$Indicators[44:nrow(lopez_df)]
)

## ------------------------------------------------------------------------------------------------------
# Correcting a typo in the data
lopez_df$Indicators[2] <- "I-2. Psychological Violence"

# Checking data types 
str(lopez_df)

# Renaming x^2 to x2
names(lopez_df)[names(lopez_df) == "x^2"] <- "x2"

# Clean data, convert to appropriate data type. 

numeric_cols <- c("x2", "Present", "Absent", "N/S", "% Valid")
lopez_df[numeric_cols] <- lapply(lopez_df[numeric_cols], function(col) {
  as.numeric(gsub(",", "", col))
})

# p-values from chi-square statistic
lopez_df$p_value <- round(pchisq(lopez_df$x2, df = 1, lower.tail = FALSE), 5)
lopez_df$significant_5pct <- lopez_df$p_value < 0.05

# Summary
num_significant <- sum(lopez_df$significant_5pct, na.rm = TRUE)
cat(sprintf("There are %d significant predictors at the 5%% level.\n", num_significant))

# Table with signeficant indicators 
significant_df <- lopez_df[lopez_df$significant_5pct == TRUE, 
                           c("Indicators", "x2", "p_value")]
kable(significant_df, caption = "Significant Predictors at the 5% Level", digits = 4)

## ------------------------------------------------------------------------------------------------------
# Histogram of p-values
ggplot(lopez_df, aes(x = p_value)) +
  geom_histogram(binwidth = 0.05, fill = "steelblue", color = "white") +
  labs(title = "Distribution of p-values",
       x = "P-value",
       y = "Count") +
  theme_minimal()

## ------------------------------------------------------------------------------------------------------
# Number of tests 
m <- nrow(lopez_df)

# Compute Bonferroni adjusted p-values
# This guide helped me understnad p.adjust function for BH, and Bonferroni.
# Title: "p.adjust: Adjust P-values for Multiple Comparisons"
# Link: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/p.adjust

lopez_df$p_bonf <- p.adjust(lopez_df$p_value, method = "bonferroni")

# Flag significant predictors under Bonferroni
lopez_df$significant_bonf <- lopez_df$p_bonf < 0.05

# Count how many predictors remain significant
num_significant_bonf <- sum(lopez_df$significant_bonf, na.rm = TRUE)
cat("Number of predictors significant after Bonferroni:", num_significant_bonf, "\n")

# How many identifiers were not significant anymore. 
lost_significance <- with(lopez_df, significant_5pct & !significant_bonf)

cat("Number of predictors that lost significance after Bonferroni:", 
    sum(lost_significance, na.rm = TRUE), "\n")

kable(lopez_df[lopez_df$significant_bonf == TRUE, 
               c("Indicators", "x2", "p_value", "p_bonf")],
      caption = "Predictors significant after Bonferroni correction", 
      digits = 4)

kable(lopez_df[lost_significance, 
               c("Indicators", "x2", "p_value", "p_bonf")],
      caption = "Predictors that lost significance after Bonferroni correction", 
      digits = 4)

## ------------------------------------------------------------------------------------------------------
# We can also get Bonferroni adjusted p-values manually

# Computation 
lopez_df$p_bonf_manual <- pmin(1, lopez_df$p_value * m)

# Confirming it's the smae as p.adjust
lopez_df$significant_bonf_manual <- lopez_df$p_bonf_manual < 0.05
sum(lopez_df$significant_bonf_manual)  

## ------------------------------------------------------------------------------------------------------
# Number of tests 
m <- nrow(lopez_df)

# P-values descending 
lopez_df$p_rank <- rank(lopez_df$p_value, ties.method = "min") 
# ties.metohd = "min" used to assigns the smallest or minimum rank to all tied 
# values/values with the same p value.

# Computing Benjamini-Hochberg adjusted FDR probabilities
lopez_df$prob_false_discovery <- pmin(1, lopez_df$p_value * m / lopez_df$p_rank)

# Identifying significant features at FDR is 5% and counting them
q <- 0.05
lopez_df$significant_BH <- lopez_df$prob_false_discovery <= q
num_significant_BH <- sum(lopez_df$significant_BH, na.rm = TRUE)

# Expected false discoveries
expected_false_discoveries <- round(q * num_significant_BH, 1)
cat("Number of significant indicators:", num_significant_BH, "\n")
cat("Expected number of false discoveries:", expected_false_discoveries, "\n")

kable(lopez_df[, c("Indicators", "p_value", "p_rank", "prob_false_discovery", "significant_BH")], 
      caption = "BH False Discovery Rate (FDR)", 
      digits = 4,
      col.names = c("Indicator", "p-value", "Rank", "FDR adj. p", "Significant"))

# Plotting 
library(ggplot2)
lopez_df_sorted <- lopez_df[order(lopez_df$p_value), ]
lopez_df_sorted$rank <- 1:m
lopez_df_sorted$bh_threshold <- (lopez_df_sorted$rank / m) * q

# Find the largest rank where p-value <= BH threshold
last_significant_rank <- max(which(lopez_df_sorted$p_value <= lopez_df_sorted$bh_threshold))

ggplot(lopez_df_sorted, aes(x = rank)) +
  geom_point(aes(y = p_value, color = significant_BH), size = 2) +
  geom_line(aes(y = bh_threshold), color = "darkred", linetype = "dashed", size = 1) +
  geom_vline(xintercept = last_significant_rank, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = c("steelblue", "firebrick"), 
                     labels = c("Not significant", "Significant (FDR 5%)")) +
  labs(title = "BH procedure and controlling false discoveries",
       x = "Rank of p-value",
       y = "p-value",
       color = "Significance") +
  theme_minimal() +
  theme(legend.position = "bottom")

## ------------------------------------------------------------------------------------------------------
m <- nrow(lopez_df)
lopez_df$p_rank <- rank(lopez_df$p_value, ties.method = "min")

# Probability that each test is a false discovery
lopez_df$prob_false_discovery <- pmin(1, lopez_df$p_value * m / lopez_df$p_rank)

kable(lopez_df[, c("Indicators", "p_value", "p_rank", "prob_false_discovery")],
      caption = "Estimated Probability Each Test is a False Discovery (Q6)",
      digits = 4)

## ------------------------------------------------------------------------------------------------------
# flaging for BH
lopez_df$significant_bh <- p.adjust(lopez_df$p_value, method = "BH") < 0.05

# Flag if significant under any test
lopez_df$significant_any <- with(lopez_df, significant_5pct | significant_bonf | significant_bh)

# Count
bonf_count <- sum(lopez_df$significant_bonf, na.rm = TRUE)
bh_count <- sum(lopez_df$significant_bh, na.rm = TRUE)
cat("Number of significant predictors:\n")
cat("Bonferroni (FWER):", bonf_count, "\n")
cat("BH (FDR):", bh_count, "\n")

# Summary
summary_df <- lopez_df[, c("Indicators", "p_value", "p_bonf", "significant_5pct", 
                           "significant_bonf", "significant_bh", "significant_any")]

# Sort by p-value and then output 
summary_df <- summary_df[order(summary_df$p_value), ]
kable(summary_df, 
      digits = 4, 
      caption = "Summary of significance across testing procedures",
      col.names = c("Indicator", "p-value", "Bonf adj p", "Sig (p<0.05)", 
                   "Sig (Bonf)", "Sig (BH)", "Sig (any)"))
